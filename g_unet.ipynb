{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We backport the U-Net into Lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nolearn.las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # in_ch x 512 x 512\\n    conv1 = Convolution(nf)(i)\\n    conv1 = BatchNorm()(conv1)\\n    x = LeakyReLU(0.2)(conv1)\\n    # nf x 256 x 256\\n\\n    conv2 = Convolution(nf * 2)(x)\\n    conv2 = BatchNorm()(conv2)\\n    x = LeakyReLU(0.2)(conv2)\\n    # nf*2 x 128 x 128\\n\\n    conv3 = Convolution(nf * 4)(x)\\n    conv3 = BatchNorm()(conv3)\\n    x = LeakyReLU(0.2)(conv3)\\n    # nf*4 x 64 x 64\\n\\n    conv4 = Convolution(nf * 8)(x)\\n    conv4 = BatchNorm()(conv4)\\n    x = LeakyReLU(0.2)(conv4)\\n    # nf*8 x 32 x 32\\n\\n    conv5 = Convolution(nf * 8)(x)\\n    conv5 = BatchNorm()(conv5)\\n    x = LeakyReLU(0.2)(conv5)\\n    # nf*8 x 16 x 16\\n\\n    conv6 = Convolution(nf * 8)(x)\\n    conv6 = BatchNorm()(conv6)\\n    x = LeakyReLU(0.2)(conv6)\\n    # nf*8 x 8 x 8\\n\\n    conv7 = Convolution(nf * 8)(x)\\n    conv7 = BatchNorm()(conv7)\\n    x = LeakyReLU(0.2)(conv7)\\n    # nf*8 x 4 x 4\\n\\n    conv8 = Convolution(nf * 8)(x)\\n    conv8 = BatchNorm()(conv8)\\n    x = LeakyReLU(0.2)(conv8)\\n    # nf*8 x 2 x 2\\n\\n    conv9 = Convolution(nf * 8, k=2, s=1, border_mode='valid')(x)\\n    conv9 = BatchNorm()(conv9)\\n    x = LeakyReLU(0.2)(conv9)\\n    # nf*8 x 1 x 1\\n\\n    dconv1 = Deconvolution(nf * 8,\\n                           get_deconv_shape(batch_size, nf * 8, 2, 2),\\n                           k=2, s=1)(x)\\n    dconv1 = BatchNorm()(dconv1)\\n    dconv1 = Dropout(0.5)(dconv1)\\n\\n    x = concatenate_layers([dconv1, conv8], **merge_params)\\n\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(8 + 8) x 2 x 2\\n\\n    dconv2 = Deconvolution(nf * 8,\\n                           get_deconv_shape(batch_size, nf * 8, 4, 4))(x)\\n    dconv2 = BatchNorm()(dconv2)\\n    dconv2 = Dropout(0.5)(dconv2)\\n    x = concatenate_layers([dconv2, conv7], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(8 + 8) x 4 x 4\\n\\n    dconv3 = Deconvolution(nf * 8,\\n                           get_deconv_shape(batch_size, nf * 8, 8, 8))(x)\\n    dconv3 = BatchNorm()(dconv3)\\n    dconv3 = Dropout(0.5)(dconv3)\\n    x = concatenate_layers([dconv3, conv6], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(8 + 8) x 8 x 8\\n\\n    dconv4 = Deconvolution(nf * 8,\\n                           get_deconv_shape(batch_size, nf * 8, 16, 16))(x)\\n    dconv4 = BatchNorm()(dconv4)\\n    x = concatenate_layers([dconv4, conv5], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(8 + 8) x 16 x 16\\n\\n    dconv5 = Deconvolution(nf * 8,\\n                           get_deconv_shape(batch_size, nf * 8, 32, 32))(x)\\n    dconv5 = BatchNorm()(dconv5)\\n    x = concatenate_layers([dconv5, conv4], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(8 + 8) x 32 x 32\\n\\n    dconv6 = Deconvolution(nf * 4,\\n                           get_deconv_shape(batch_size, nf * 4, 64, 64))(x)\\n    dconv6 = BatchNorm()(dconv6)\\n    x = concatenate_layers([dconv6, conv3], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(4 + 4) x 64 x 64\\n\\n    dconv7 = Deconvolution(nf * 2,\\n                           get_deconv_shape(batch_size, nf * 2, 128, 128))(x)\\n    dconv7 = BatchNorm()(dconv7)\\n    x = concatenate_layers([dconv7, conv2], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(2 + 2) x 128 x 128\\n\\n    dconv8 = Deconvolution(nf,\\n                           get_deconv_shape(batch_size, nf, 256, 256))(x)\\n    dconv8 = BatchNorm()(dconv8)\\n    x = concatenate_layers([dconv8, conv1], **merge_params)\\n    x = LeakyReLU(0.2)(x)\\n    # nf*(1 + 1) x 256 x 256\\n\\n    dconv9 = Deconvolution(out_ch,\\n                           get_deconv_shape(batch_size, out_ch, 512, 512))(x)\\n    # out_ch x 512 x 512\\n\\n    act = 'sigmoid' if is_binary else 'tanh'\\n    out = Activation(act)(dconv9)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    # in_ch x 512 x 512\n",
    "    conv1 = Convolution(nf)(i)\n",
    "    conv1 = BatchNorm()(conv1)\n",
    "    x = LeakyReLU(0.2)(conv1)\n",
    "    # nf x 256 x 256\n",
    "\n",
    "    conv2 = Convolution(nf * 2)(x)\n",
    "    conv2 = BatchNorm()(conv2)\n",
    "    x = LeakyReLU(0.2)(conv2)\n",
    "    # nf*2 x 128 x 128\n",
    "\n",
    "    conv3 = Convolution(nf * 4)(x)\n",
    "    conv3 = BatchNorm()(conv3)\n",
    "    x = LeakyReLU(0.2)(conv3)\n",
    "    # nf*4 x 64 x 64\n",
    "\n",
    "    conv4 = Convolution(nf * 8)(x)\n",
    "    conv4 = BatchNorm()(conv4)\n",
    "    x = LeakyReLU(0.2)(conv4)\n",
    "    # nf*8 x 32 x 32\n",
    "\n",
    "    conv5 = Convolution(nf * 8)(x)\n",
    "    conv5 = BatchNorm()(conv5)\n",
    "    x = LeakyReLU(0.2)(conv5)\n",
    "    # nf*8 x 16 x 16\n",
    "\n",
    "    conv6 = Convolution(nf * 8)(x)\n",
    "    conv6 = BatchNorm()(conv6)\n",
    "    x = LeakyReLU(0.2)(conv6)\n",
    "    # nf*8 x 8 x 8\n",
    "\n",
    "    conv7 = Convolution(nf * 8)(x)\n",
    "    conv7 = BatchNorm()(conv7)\n",
    "    x = LeakyReLU(0.2)(conv7)\n",
    "    # nf*8 x 4 x 4\n",
    "\n",
    "    conv8 = Convolution(nf * 8)(x)\n",
    "    conv8 = BatchNorm()(conv8)\n",
    "    x = LeakyReLU(0.2)(conv8)\n",
    "    # nf*8 x 2 x 2\n",
    "\n",
    "    conv9 = Convolution(nf * 8, k=2, s=1, border_mode='valid')(x)\n",
    "    conv9 = BatchNorm()(conv9)\n",
    "    x = LeakyReLU(0.2)(conv9)\n",
    "    # nf*8 x 1 x 1\n",
    "\n",
    "    dconv1 = Deconvolution(nf * 8,\n",
    "                           get_deconv_shape(batch_size, nf * 8, 2, 2),\n",
    "                           k=2, s=1)(x)\n",
    "    dconv1 = BatchNorm()(dconv1)\n",
    "    dconv1 = Dropout(0.5)(dconv1)\n",
    "\n",
    "    x = concatenate_layers([dconv1, conv8], **merge_params)\n",
    "\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(8 + 8) x 2 x 2\n",
    "\n",
    "    dconv2 = Deconvolution(nf * 8,\n",
    "                           get_deconv_shape(batch_size, nf * 8, 4, 4))(x)\n",
    "    dconv2 = BatchNorm()(dconv2)\n",
    "    dconv2 = Dropout(0.5)(dconv2)\n",
    "    x = concatenate_layers([dconv2, conv7], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(8 + 8) x 4 x 4\n",
    "\n",
    "    dconv3 = Deconvolution(nf * 8,\n",
    "                           get_deconv_shape(batch_size, nf * 8, 8, 8))(x)\n",
    "    dconv3 = BatchNorm()(dconv3)\n",
    "    dconv3 = Dropout(0.5)(dconv3)\n",
    "    x = concatenate_layers([dconv3, conv6], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(8 + 8) x 8 x 8\n",
    "\n",
    "    dconv4 = Deconvolution(nf * 8,\n",
    "                           get_deconv_shape(batch_size, nf * 8, 16, 16))(x)\n",
    "    dconv4 = BatchNorm()(dconv4)\n",
    "    x = concatenate_layers([dconv4, conv5], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(8 + 8) x 16 x 16\n",
    "\n",
    "    dconv5 = Deconvolution(nf * 8,\n",
    "                           get_deconv_shape(batch_size, nf * 8, 32, 32))(x)\n",
    "    dconv5 = BatchNorm()(dconv5)\n",
    "    x = concatenate_layers([dconv5, conv4], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(8 + 8) x 32 x 32\n",
    "\n",
    "    dconv6 = Deconvolution(nf * 4,\n",
    "                           get_deconv_shape(batch_size, nf * 4, 64, 64))(x)\n",
    "    dconv6 = BatchNorm()(dconv6)\n",
    "    x = concatenate_layers([dconv6, conv3], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(4 + 4) x 64 x 64\n",
    "\n",
    "    dconv7 = Deconvolution(nf * 2,\n",
    "                           get_deconv_shape(batch_size, nf * 2, 128, 128))(x)\n",
    "    dconv7 = BatchNorm()(dconv7)\n",
    "    x = concatenate_layers([dconv7, conv2], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(2 + 2) x 128 x 128\n",
    "\n",
    "    dconv8 = Deconvolution(nf,\n",
    "                           get_deconv_shape(batch_size, nf, 256, 256))(x)\n",
    "    dconv8 = BatchNorm()(dconv8)\n",
    "    x = concatenate_layers([dconv8, conv1], **merge_params)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # nf*(1 + 1) x 256 x 256\n",
    "\n",
    "    dconv9 = Deconvolution(out_ch,\n",
    "                           get_deconv_shape(batch_size, out_ch, 512, 512))(x)\n",
    "    # out_ch x 512 x 512\n",
    "\n",
    "    act = 'sigmoid' if is_binary else 'tanh'\n",
    "    out = Activation(act)(dconv9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Convolution(layer, f, k=3, s=2, border_mode='same', **kwargs):\n",
    "    \"\"\"Convenience method for Convolutions.\"\"\"\n",
    "    \"\"\"\n",
    "    if KERAS_2:\n",
    "        return Convolution2D(f,\n",
    "                             kernel_size=(k, k),\n",
    "                             padding=border_mode,\n",
    "                             strides=(s, s),\n",
    "                             **kwargs)\n",
    "    else:\n",
    "        return Convolution2D(f, k, k, border_mode=border_mode,\n",
    "                             subsample=(s, s),\n",
    "                             **kwargs)\n",
    "    \"\"\"\n",
    "    \n",
    "    return Conv2DLayer(layer, num_filters=f, filter_size=(k,k), stride=(s,s), pad=border_mode, nonlinearity=linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Deconvolution(layer, f, k=2, s=2, **kwargs):\n",
    "    \"\"\"Convenience method for Transposed Convolutions.\"\"\"\n",
    "    \"\"\"\n",
    "    if KERAS_2:\n",
    "        return Conv2DTranspose(f,\n",
    "                               kernel_size=(k, k),\n",
    "                               strides=(s, s),\n",
    "                               data_format=K.image_data_format(),\n",
    "                               **kwargs)\n",
    "    else:\n",
    "        return Deconvolution2D(f, k, k, output_shape=output_shape,\n",
    "                               subsample=(s, s), **kwargs)\n",
    "    \"\"\"\n",
    "    return Deconv2DLayer(layer, num_filters=f, filter_size=(k,k), stride=(s,s), nonlinearity=linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_layers(layers, **kwargs):\n",
    "    return ConcatLayer(layers, axis=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deconv_shape(*args, **kwargs):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 28, 512, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = InputLayer((None, 1, 512, 512))\n",
    "Convolution(i, 28).output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g_unet():\n",
    "    i = InputLayer((None, 1, 512, 512))\n",
    "    \n",
    "    nf=64\n",
    "    \n",
    "    # in_ch x 512 x 512\n",
    "    conv1 = Convolution(i, nf)\n",
    "    conv1 = BatchNormLayer(conv1)\n",
    "    x = NonlinearityLayer(conv1, nonlinearity=leaky_rectify)\n",
    "    # nf x 256 x 256\n",
    "\n",
    "    conv2 = Convolution(x, nf * 2)\n",
    "    conv2 = BatchNormLayer(conv2)\n",
    "    x = NonlinearityLayer(conv2, nonlinearity=leaky_rectify)\n",
    "    # nf*2 x 128 x 128\n",
    "\n",
    "    conv3 = Convolution(x, nf * 4)\n",
    "    conv3 = BatchNormLayer(conv3)\n",
    "    x = NonlinearityLayer(conv3, nonlinearity=leaky_rectify)\n",
    "    # nf*4 x 64 x 64\n",
    "\n",
    "    conv4 = Convolution(x, nf * 8)\n",
    "    conv4 = BatchNormLayer(conv4)\n",
    "    x = NonlinearityLayer(conv4, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 32 x 32\n",
    "\n",
    "    conv5 = Convolution(x, nf * 8)\n",
    "    conv5 = BatchNormLayer(conv5)\n",
    "    x = NonlinearityLayer(conv5, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 16 x 16\n",
    "\n",
    "    conv6 = Convolution(x, nf * 8)\n",
    "    conv6 = BatchNormLayer(conv6)\n",
    "    x = NonlinearityLayer(conv6, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 8 x 8\n",
    "\n",
    "    conv7 = Convolution(x, nf * 8)\n",
    "    conv7 = BatchNormLayer(conv7)\n",
    "    x = NonlinearityLayer(conv7, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 4 x 4\n",
    "\n",
    "    conv8 = Convolution(x, nf * 8)\n",
    "    conv8 = BatchNormLayer(conv8)\n",
    "    x = NonlinearityLayer(conv8, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 2 x 2\n",
    "\n",
    "    conv9 = Convolution(x, nf * 8, k=2, s=1, border_mode='valid')\n",
    "    conv9 = BatchNormLayer(conv9)\n",
    "    x = NonlinearityLayer(conv9, nonlinearity=leaky_rectify)\n",
    "    # nf*8 x 1 x 1  \n",
    "\n",
    "    dconv1 = Deconvolution(x, nf * 8,\n",
    "                           k=2, s=1)\n",
    "    dconv1 = BatchNormLayer(dconv1)\n",
    "    dconv1 = DropoutLayer(dconv1, 0.5)\n",
    "\n",
    "    x = concatenate_layers([dconv1, conv8])\n",
    "\n",
    "    x = NonlinearityLayer(x, nonlinearity=leaky_rectify)\n",
    "    # nf*(8 + 8) x 2 x 2\n",
    "\n",
    "    dconv2 = Deconvolution(x, nf * 8)\n",
    "    dconv2 = BatchNormLayer(dconv2)\n",
    "    dconv2 = DropoutLayer(dconv2, 0.5)\n",
    "    x = concatenate_layers([dconv2, conv7])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(8 + 8) x 4 x 4\n",
    "\n",
    "    dconv3 = Deconvolution(x, nf * 8)\n",
    "    dconv3 = BatchNormLayer(dconv3)\n",
    "    dconv3 = DropoutLayer(dconv3, 0.5)\n",
    "    x = concatenate_layers([dconv3, conv6])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(8 + 8) x 8 x 8\n",
    "\n",
    "    dconv4 = Deconvolution(x, nf * 8)\n",
    "    dconv4 = BatchNormLayer(dconv4)\n",
    "    x = concatenate_layers([dconv4, conv5])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(8 + 8) x 16 x 16\n",
    "    \n",
    "\n",
    "    dconv5 = Deconvolution(x, nf * 8)\n",
    "    dconv5 = BatchNormLayer(dconv5)\n",
    "    x = concatenate_layers([dconv5, conv4])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(8 + 8) x 32 x 32\n",
    "\n",
    "    dconv6 = Deconvolution(x, nf * 4)\n",
    "    dconv6 = BatchNormLayer(dconv6)\n",
    "    x = concatenate_layers([dconv6, conv3])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(4 + 4) x 64 x 64\n",
    "\n",
    "    dconv7 = Deconvolution(x, nf * 2)\n",
    "    dconv7 = BatchNormLayer(dconv7)\n",
    "    x = concatenate_layers([dconv7, conv2])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(2 + 2) x 128 x 128\n",
    "    \n",
    "    dconv8 = Deconvolution(x, nf)\n",
    "    dconv8 = BatchNormLayer(dconv8)\n",
    "    x = concatenate_layers([dconv8, conv1])\n",
    "    x = NonlinearityLayer(x, leaky_rectify)\n",
    "    # nf*(1 + 1) x 256 x 256\n",
    "        \n",
    "    dconv9 = Deconvolution(x, 3)\n",
    "    # out_ch x 512 x 512\n",
    "\n",
    "    #act = 'sigmoid' if is_binary else 'tanh'\n",
    "    act = tanh\n",
    "    out = NonlinearityLayer(dconv9, act)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_out = g_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x7f1ec80d5c50> (None, 1, 512, 512)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec81d3390> (None, 64, 256, 256)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec812bbd0> (None, 64, 256, 256)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec7ff8cd0> (None, 64, 256, 256)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec83f1210> (None, 128, 128, 128)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec83f1950> (None, 128, 128, 128)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8254690> (None, 128, 128, 128)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec82546d0> (None, 256, 64, 64)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec82549d0> (None, 256, 64, 64)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8254210> (None, 256, 64, 64)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8254050> (None, 512, 32, 32)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8241dd0> (None, 512, 32, 32)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec82416d0> (None, 512, 32, 32)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec82414d0> (None, 512, 16, 16)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8241210> (None, 512, 16, 16)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8025110> (None, 512, 16, 16)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec80253d0> (None, 512, 8, 8)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8025410> (None, 512, 8, 8)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8025c10> (None, 512, 8, 8)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8025d90> (None, 512, 4, 4)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8025f10> (None, 512, 4, 4)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec80205d0> (None, 512, 4, 4)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8020750> (None, 512, 2, 2)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec80208d0> (None, 512, 2, 2)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8020f50> (None, 512, 2, 2)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec802d110> (None, 512, 1, 1)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec802d290> (None, 512, 1, 1)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec802d910> (None, 512, 1, 1)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec802da90> (None, 512, 2, 2)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec802dc10> (None, 512, 2, 2)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7f1ec80142d0> (None, 512, 2, 2)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec8014490> (None, 1024, 2, 2)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec80144d0> (None, 1024, 2, 2)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec8014510> (None, 512, 4, 4)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8014690> (None, 512, 4, 4)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7f1ec801ddd0> (None, 512, 4, 4)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec801df90> (None, 1024, 4, 4)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec801de10> (None, 1024, 4, 4)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec801ded0> (None, 512, 8, 8)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec7ff6390> (None, 512, 8, 8)\n",
      "<lasagne.layers.noise.DropoutLayer object at 0x7f1ec800d210> (None, 512, 8, 8)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec8191d10> (None, 1024, 8, 8)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8191950> (None, 1024, 8, 8)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec81919d0> (None, 512, 16, 16)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec8191e10> (None, 512, 16, 16)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec8191210> (None, 1024, 16, 16)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec818d050> (None, 1024, 16, 16)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec818d350> (None, 512, 32, 32)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec818d810> (None, 512, 32, 32)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec818d8d0> (None, 1024, 32, 32)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec80d5dd0> (None, 1024, 32, 32)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec80d5c10> (None, 256, 64, 64)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec80d5b90> (None, 256, 64, 64)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec8083b10> (None, 512, 64, 64)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8083bd0> (None, 512, 64, 64)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec8083810> (None, 128, 128, 128)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec80837d0> (None, 128, 128, 128)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec807fc50> (None, 256, 128, 128)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec807fbd0> (None, 256, 128, 128)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec807f0d0> (None, 64, 256, 256)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x7f1ec807f090> (None, 64, 256, 256)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x7f1ec8187710> (None, 128, 256, 256)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8081990> (None, 128, 256, 256)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x7f1ec8081590> (None, 3, 512, 512)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec80a3690> (None, 3, 512, 512)\n",
      "22882243\n"
     ]
    }
   ],
   "source": [
    "for layer in get_all_layers(l_out):\n",
    "    print layer, layer.output_shape\n",
    "print count_params(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    nf = 32\n",
    "\n",
    "    i = InputLayer((None, 4, 512, 512))\n",
    "\n",
    "    # (a_ch + b_ch) x 512 x 512\n",
    "    conv1 = Convolution(i,nf)\n",
    "    x = NonlinearityLayer(conv1, leaky_rectify)\n",
    "    # nf x 256 x 256\n",
    "\n",
    "    conv2 = Convolution(x, nf * 2)\n",
    "    x = NonlinearityLayer(conv2, leaky_rectify)\n",
    "    # nf*2 x 128 x 128\n",
    "\n",
    "    conv3 = Convolution(x, nf * 4)\n",
    "    x = NonlinearityLayer(conv3, leaky_rectify)\n",
    "    # nf*4 x 64 x 64\n",
    "\n",
    "    conv4 = Convolution(x, nf * 8)\n",
    "    x = NonlinearityLayer(conv4, leaky_rectify)\n",
    "    # nf*8 x 32 x 32\n",
    "\n",
    "    conv5 = Convolution(x, 1)\n",
    "    out = NonlinearityLayer(conv5, sigmoid)\n",
    "    # 1 x 16 x 16\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x7f1ec8222590> (None, 4, 512, 512)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8076e10> (None, 32, 256, 256)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec80767d0> (None, 32, 256, 256)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8076050> (None, 64, 128, 128)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8076710> (None, 64, 128, 128)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec825ed90> (None, 128, 64, 64)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec825e190> (None, 128, 64, 64)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec82df5d0> (None, 256, 32, 32)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8188e50> (None, 256, 32, 32)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x7f1ec8188c90> (None, 1, 16, 16)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x7f1ec8188f10> (None, 1, 16, 16)\n",
      "391009\n"
     ]
    }
   ],
   "source": [
    "l_out = discriminator()\n",
    "for layer in get_all_layers(l_out):\n",
    "    print layer, layer.output_shape\n",
    "print count_params(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
